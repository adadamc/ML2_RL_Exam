{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7d19b4-4cc0-49c5-8027-376d46ebb41d",
   "metadata": {},
   "source": [
    "# ML2 (CSCI 4052U) Exam: RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921bde35-13a8-4eee-8f71-ed0881daa1c6",
   "metadata": {},
   "source": [
    "Installs:\n",
    "- pip install gymnasium\n",
    "- pip install swig\n",
    "- pip install \"gymnasium[box2d]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75bdd798-760b-4948-ab77-d4a809cfa6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464e6b58-c9bf-4b8c-8ca4-69184f1e1898",
   "metadata": {},
   "source": [
    "Lunar Lander Page: https://gymnasium.farama.org/environments/box2d/lunar_lander/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0404ef5b-3ba6-4ddc-80c9-cec70f6fcf55",
   "metadata": {},
   "source": [
    "64 possible states, 4 actions (left, down, right, up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f8e943a7-ef6e-42d4-933d-942c2cf3ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Runs the requested amount of episodes using Q-Learning\n",
    "# episodes = # of episodes to run through\n",
    "# learning_rate\n",
    "# discount_factor = 0 to 1, closer to 1 values future rewards highly, closer to 0 focuses on immediate rewards more\n",
    "# epsilon = 0 to 1, chance of taking a random action (1 is always random, 0 is always optimal action as per q values)\n",
    "# epsilon_change = how much to lower epsilon by per episode (over time max q-value should take priority and exploration minimized)\n",
    "# slippery = If False, the action requested is always followed through on. If True, the action requested is followed through on 1/3 of the time,\n",
    "#            and the two perpendicular actions are taken 1/3 of the time each (ex. request=left (1/3 chance), 1/3 chance of slipping up, 1/3 of down)\n",
    "# render = None for no visualization, \"Human\" to see visualization\n",
    "\n",
    "def run_episodes(episodes, learning_rate=0.9, discount_factor=0.9, epsilon=1, epsilon_change=0.01, slippery=True, render=None, debug=False):\n",
    "    env = gym.make(\"FrozenLake-v1\", map_name=\"8x8\", is_slippery=slippery, render_mode=render)\n",
    "\n",
    "    # 64 states (0 to 63) and 4 actions (0 = left, 1 = down, 2 = right, 3 = up)\n",
    "    q = np.zeros((env.observation_space.n, env.action_space.n)) # q-value storage\n",
    "    rng = np.random.default_rng() # random number from 0 to 1 (to determine if random action should be taken)\n",
    "    completions = np.full(episodes,False)\n",
    "    checkpoints = math.floor(episodes/10) # Print statement at 10% completion intervals\n",
    "\n",
    "    for _ in range(episodes):\n",
    "        state, info = env.reset()\n",
    "\n",
    "        if debug:\n",
    "            print(\"Episode\", _, \" , Epsilon:\", epsilon)\n",
    "        elif (_+1)%checkpoints==0:\n",
    "            print(\"Episode\", _, \" , Epsilon:\", round(epsilon,3), \" | Completions so Far:\", completions.sum(), \" | Success Rate so Far:\", round(completions.sum()/_,3)*100,\"%\")\n",
    "            \n",
    "\n",
    "        while True:\n",
    "\n",
    "            if rng.random() < epsilon:\n",
    "                action = env.action_space.sample() # Random action\n",
    "            else:\n",
    "                action = np.argmax(q[state,:])\n",
    "\n",
    "            # new_state: After taking the action calculated above, what position are we now in? (0-63)\n",
    "            # reward: The reward for taking that action (reach goal = +1, reach hole/frozen = 0)\n",
    "            # terminated: True if the player moves into a hole OR the player reaches the goal\n",
    "            # truncation: True if the limit (length of episode) is reached, this is 200 for 8x8 env\n",
    "            # info: number from 0 to 1 with odds of taking the action requested (1/3 if is_slippery, 1 otherwise)\n",
    "            new_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            if reward == 1:\n",
    "                completions[_] = True\n",
    "\n",
    "            q[state,action] = q[state,action] + learning_rate * (reward + discount_factor * max(q[new_state,:]) -q[state,action])\n",
    "\n",
    "            state = new_state\n",
    "\n",
    "            if terminated or truncated:\n",
    "                if render == \"Human\":\n",
    "                    time.sleep(0.05)\n",
    "                break\n",
    "\n",
    "        epsilon -= epsilon_change # Lower Epsilon by specified amount\n",
    "        if epsilon < 0:\n",
    "            epsilon = 0\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    env.close()\n",
    "    print(\"\\nSimple Breakdown:\")\n",
    "    print(\"Episodes:\", episodes)\n",
    "    print(\"Successful Episodes:\", completions.sum())\n",
    "    print(\"Failed Episodes:\", (episodes-completions.sum()))\n",
    "    print(\"Success Rate:\", round(((completions.sum())/(episodes))*100,3), \"%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9e393fae-bdeb-4765-8ef0-5d3a97de28aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6999  , Epsilon: 0.86  | Completions so Far: 38  | Success Rate so Far: 0.5 %\n",
      "Episode 13999  , Epsilon: 0.72  | Completions so Far: 125  | Success Rate so Far: 0.8999999999999999 %\n",
      "Episode 20999  , Epsilon: 0.58  | Completions so Far: 398  | Success Rate so Far: 1.9 %\n",
      "Episode 27999  , Epsilon: 0.44  | Completions so Far: 1200  | Success Rate so Far: 4.3 %\n",
      "Episode 34999  , Epsilon: 0.3  | Completions so Far: 3016  | Success Rate so Far: 8.6 %\n",
      "Episode 41999  , Epsilon: 0.16  | Completions so Far: 6557  | Success Rate so Far: 15.6 %\n",
      "Episode 48999  , Epsilon: 0.02  | Completions so Far: 12173  | Success Rate so Far: 24.8 %\n",
      "Episode 55999  , Epsilon: 0  | Completions so Far: 19155  | Success Rate so Far: 34.2 %\n",
      "Episode 62999  , Epsilon: 0  | Completions so Far: 26155  | Success Rate so Far: 41.5 %\n",
      "Episode 69999  , Epsilon: 0  | Completions so Far: 33155  | Success Rate so Far: 47.4 %\n",
      "\n",
      "Simple Breakdown:\n",
      "Episodes: 70000\n",
      "Successful Episodes: 33156\n",
      "Failed Episodes: 36844\n",
      "Success Rate: 47.366 %\n"
     ]
    }
   ],
   "source": [
    "# render=\"Human\" to visualize\n",
    "run_episodes(70000, epsilon_change=0.00002, slippery=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f4c66-ebbc-4622-bb42-51e655738fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774cdc2-3f65-4426-96f3-ae0cde053d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7b6a03a-ae2f-4a1d-90f1-9580ca55e230",
   "metadata": {},
   "source": [
    "Research Resources:\n",
    "- AI (CSCI 4610U) Lectures\n",
    "- ML2 (CSCI 4052U) Lectures\n",
    "- https://www.youtube.com/watch?v=ZhoIgo3qqLU - FrozenLake Gymnasium\n",
    "- https://gymnasium.farama.org/environments/toy_text/frozen_lake/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "13ed652e-e1fa-459f-ae3a-ffec891b2987",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.close() # Run to  manually close environment if error occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b4906-7ee8-4605-ba00-b3d2d998d429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
